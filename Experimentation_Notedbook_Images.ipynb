{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "idea = \"Rainbow tapioca boba that comes in fruit flavors color coordinated to the fruit. The boba is ready made and dried and you just add water to rehydrate it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/owenburns/.cache/huggingface/hub/models--nlpconnect--vit-gpt2-image-captioning/snapshots/dc68f91c06a1ba6f15268e5b9c13ae7a7c514084 were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.11.crossattention.masked_bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.5.attn.masked_bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.5.crossattention.bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'a vintage photo of a man standing on a vintage model airplane '}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"/Users/owenburns/.cache/huggingface/hub/models--nlpconnect--vit-gpt2-image-captioning/snapshots/dc68f91c06a1ba6f15268e5b9c13ae7a7c514084\")\n",
    "\n",
    "print(image_to_text(\"patent_diagram.png\"))\n",
    "# image_text = []\n",
    "# for image in images:\n",
    "#     image = Image.open(image)\n",
    "#     image_text.append(image_to_text(image)[0]['generated_text'])\n",
    "\n",
    "# image_txts = '\\n\\t- '.join(image_text)\n",
    "# idea_processed = f\"{idea} \\ndescription of figures:\\n{image_txts}\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import tqdm\n",
    "url = \"/Users/owenburns/Downloads/US10078367.pdf\"\n",
    "doc = fitz.Document(url)\n",
    "for i in range(doc.page_count):\n",
    "    for j, img in enumerate(doc.get_page_images(i)):\n",
    "        xref = img[0]\n",
    "        image = doc.extract_image(xref)\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        pix.save(\"%s_p%s-%s.png\" % (j, i, xref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(617.0, 21.14481), (759.4953, 21.050911), (765.133484, 26.475544), (765.161865, 513.234985), (759.255981, 519.030029), (519.763794, 519.03009), (513.947144, 513.117493), (514.076965, 337.932892), (509.279022, 332.983582), (478.783875, 333.054474)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "path = \"\"\"M617.000000,21.144810 \n",
    "\tC664.831848,21.144812 712.163940,21.199860 759.495300,21.050911 \n",
    "\tC763.747803,21.037529 765.136902,21.890913 765.133484,26.475544 \n",
    "\tC765.013000,188.728668 765.021729,350.981934 765.161865,513.234985 \n",
    "\tC765.165955,517.980164 763.798889,519.037659 759.255981,519.030029 \n",
    "\tC679.425354,518.896301 599.594421,518.895386 519.763794,519.030090 \n",
    "\tC515.114624,519.037903 513.934937,517.784790 513.947144,513.117493 \n",
    "\tC514.099365,454.722931 513.981201,396.327728 514.076965,337.932892 \n",
    "\tC514.083130,334.166229 513.343262,332.851562 509.279022,332.983582 \n",
    "\tC499.123383,333.313385 488.949310,333.150757 478.783875,333.054474 \n",
    "\tC475.975189,333.027863 473.799683,333.085022 474.409668,336.917053 \n",
    "\tC474.662292,338.504211 473.944000,339.184204 471.989990,338.465881 \n",
    "\tC465.976837,336.255493 459.858917,334.330170 452.422424,331.838623 \n",
    "\tC459.816223,329.295654 465.820831,327.209564 471.841797,325.171844 \n",
    "\tC473.770569,324.519073 474.798096,325.193420 474.414215,327.320953 \n",
    "\tC473.886139,330.247681 475.778503,330.117920 477.727509,330.113831 \n",
    "\tC488.893768,330.090363 500.063568,329.945618 511.224365,330.193054 \n",
    "\tC514.641846,330.268829 513.989441,328.351044 513.989990,326.462738 \n",
    "\tC513.997009,301.163849 513.995422,275.864960 513.995361,250.566086 \n",
    "\tC513.995239,197.183258 513.955139,143.800339 514.074951,90.417786 \n",
    "\tC514.083862,86.444405 513.350220,85.150955 508.983093,85.373184 \n",
    "\tC498.688293,85.897034 488.355408,85.723984 478.038055,85.714241 \n",
    "\tC475.760529,85.712090 474.092590,85.935776 474.329071,88.779877 \n",
    "\tC474.574005,91.726166 472.967194,90.983574 471.248993,90.383942 \n",
    "\tC467.489624,89.071999 463.649017,87.986954 459.914368,86.611656 \n",
    "\tC456.174286,85.234360 454.001892,84.863594 454.453705,90.362579 \n",
    "\tC455.033539,97.420128 454.357239,104.571899 454.646820,111.665733 \n",
    "\tC454.812012,115.710945 453.327393,116.635277 449.505951,116.623871 \n",
    "\tC408.340942,116.501045 367.175385,116.547302 326.010010,116.547325 \n",
    "\tC298.177551,116.547340 270.344513,116.630013 242.513245,116.449127 \n",
    "\tC238.781189,116.424873 237.668167,117.377937 237.749481,121.069275 \n",
    "\tC237.983383,131.687363 237.954681,142.313492 237.855057,152.934845 \n",
    "\tC237.833878,155.191605 238.123596,156.438156 240.717712,156.123184 \n",
    "\tC242.787476,155.871872 243.327850,156.810654 242.638107,158.774933 \n",
    "\tC240.569168,164.666916 238.587997,170.589706 236.084274,177.932587 \n",
    "\tC233.543716,170.446823 231.454865,164.271011 229.347748,158.101425 \n",
    "\tC228.936066,156.896011 229.277023,155.946136 230.570679,156.134064 \n",
    "\tC234.999588,156.777496 234.284943,153.748367 234.286530,151.177551 \n",
    "\tC234.292618,141.236298 234.182785,131.292877 234.366928,121.354904 \n",
    "\tC234.435333,117.663116 233.448135,116.436546 229.451080,116.444946 \n",
    "\tC161.453506,116.587830 93.455528,116.547386 25.457645,116.547295 \n",
    "\tC17.698822,116.547287 17.719671,116.547058 17.722347,108.933075 \n",
    "\tC17.732016,81.425949 17.808622,53.918308 17.635632,26.412273 \n",
    "\tC17.610428,22.404724 18.444271,21.046089 22.752296,21.049578 \n",
    "\tC164.914444,21.164728 307.076721,21.159147 449.238892,21.070705 \n",
    "\tC453.214661,21.068232 454.681335,21.875347 454.625702,26.250980 \n",
    "\tC454.399719,44.020691 454.715393,61.796837 454.563904,79.568336 \n",
    "\tC454.535370,82.915260 455.253784,83.212700 458.115662,82.139778 \n",
    "\tC462.609406,80.455040 467.259003,79.190559 471.790619,77.599998 \n",
    "\tC473.579437,76.972145 474.768158,76.743057 474.436249,79.231949 \n",
    "\tC474.056091,82.082634 475.651581,82.513893 478.025238,82.498161 \n",
    "\tC488.691101,82.427521 499.365265,82.236794 510.020203,82.585426 \n",
    "\tC514.107727,82.719162 514.120728,80.740425 514.111328,77.859680 \n",
    "\tC514.054871,60.575005 514.224670,43.287498 513.940674,26.007153 \n",
    "\tC513.872192,21.841005 515.177734,21.050364 519.003296,21.066488 \n",
    "\tC551.501770,21.203487 584.000977,21.144814 617.000000,21.144810 \n",
    "z\"\"\"\n",
    "\n",
    "lines = path.replace(\"\t\", \"\").split(\"\\n\")\n",
    "points = [tuple(float(x) for x in lines[0][1:-1].split(\",\"))]\n",
    "lines = lines[1:-1]\n",
    "for line in lines:\n",
    "    points.append(tuple(float(x) for x in line[1:-1].split(\" \")[2].split(\",\")))\n",
    "\n",
    "# plot as-is\n",
    "# points = np.array(points)\n",
    "print(points[:10])\n",
    "# plt.plot(points[:, 1], points[:, 0])\n",
    "\n",
    "image = Image.new(\"RGB\", (1000, 1000), \"white\")\n",
    "draw = ImageDraw.Draw(image)\n",
    "draw.line(points, width=0, fill=\"black\")\n",
    "image.save(\"/Users/owenburns/Desktop/lines.png\")\n",
    "\n",
    "\n",
    "# image = Image.new(\"RGB\", (400, 400), \"red\")\n",
    "# points = [(100, 100), (150, 200), (200, 50), (400, 400)]\n",
    "# draw = ImageDraw.Draw(image)\n",
    "# draw.line(points, width=15, fill=\"green\", joint=\"curve\")\n",
    "# image.save(\"/Users/owenburns/Desktop/lines.png\")\n",
    "# plt.clf()\n",
    "\n",
    "# # remove the shortest line segments\n",
    "\n",
    "# line_segments = [points[i:i+2] for i in range(len(points)-1)]\n",
    "# line_segments.append([points[-1], points[0]])\n",
    "# line_segments = np.array(line_segments)\n",
    "\n",
    "# def line_length(line):\n",
    "# \treturn np.sqrt((line[0][0] - line[1][0])**2 + (line[0][1] - line[1][1])**2)\n",
    "\n",
    "# line_lengths = np.array([line_length(line) for line in line_segments])\n",
    "# q1 = np.quantile(line_lengths, 0.5)\n",
    "# line_segments = line_segments[np.where(line_lengths > q1)]\n",
    "\n",
    "# new_points = np.concatenate(line_segments)\n",
    "# plt.plot(new_points[:, 1], new_points[:, 0], \"o-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"/Users/owenburns/Desktop/Screenshot 2023-06-22 at 10.25.07 AM.png\", 0)\n",
    "_, binary_image = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "edges = cv2.Canny(image=binary_image, threshold1=100, threshold2=200)\n",
    "cv2.imwrite(\"/Users/owenburns/Desktop/edges.png\", edges)\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "line_image = np.copy(img) * 0\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "\n",
    "cv2.imwrite(\"/Users/owenburns/Desktop/lines.png\", line_image)\n",
    "\n",
    "# img_blur = cv2.GaussianBlur(img, (3,3), 0) \n",
    "\n",
    "# cv2.imwrite(\"/Users/owenburns/Desktop/edges.png\", edges)\n",
    "# def preprocess(img):\n",
    "#     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     img_blur = cv2.GaussianBlur(img_gray, (5, 5), 1)\n",
    "#     img_canny = cv2.Canny(img_blur, 50, 50)\n",
    "#     kernel = np.ones((3, 3))\n",
    "#     img_dilate = cv2.dilate(img_canny, kernel, iterations=2)\n",
    "#     img_erode = cv2.erode(img_dilate, kernel, iterations=1)\n",
    "#     return img_erode\n",
    "\n",
    "# def find_tip(points, convex_hull):\n",
    "#     length = len(points)\n",
    "#     indices = np.setdiff1d(range(length), convex_hull)\n",
    "\n",
    "#     for i in range(2):\n",
    "#         j = indices[i] + 2\n",
    "#         if j > length - 1:\n",
    "#             j = length - j\n",
    "#         if np.all(points[j] == points[indices[i - 1] - 2]):\n",
    "#             return tuple(points[j])\n",
    "        \n",
    "# contours, hierarchy = cv2.findContours(preprocess(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# for cnt in contours:\n",
    "#     peri = cv2.arcLength(cnt, True)\n",
    "#     approx = cv2.approxPolyDP(cnt, 0.025 * peri, True)\n",
    "#     hull = cv2.convexHull(approx, returnPoints=False)\n",
    "#     sides = len(hull)\n",
    "\n",
    "#     if 6 > sides > 3 and sides + 2 == len(approx):\n",
    "#         arrow_tip = find_tip(approx[:,0,:], hull.squeeze())\n",
    "#         if arrow_tip:\n",
    "#             cv2.drawContours(img, [cnt], -1, (0, 255, 0), 3)\n",
    "#             cv2.circle(img, arrow_tip, 3, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "# cv2.imwrite(\"/Users/owenburns/Desktop/arrow.png\", img)\n",
    "\n",
    "\n",
    "# gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# blur = cv2.bilateralFilter(gray, 16, 50, 50)\n",
    "\n",
    "# corners = cv2.goodFeaturesToTrack(blur, 40, 0.1, 10)\n",
    "# corners = np.int0(corners)\n",
    "\n",
    "# for i in corners:\n",
    "#     x,y = i.ravel()\n",
    "#     cv2.circle(img,(x,y),3,255,-1)\n",
    "\n",
    "# cv2.circle(img, (x, y), 3, 255, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `SearchPatents` with `SELECT publication_number, title_localized.text AS title FROM `patents-public-data.patents.publications`, UNNEST(title_localized) AS title_localized WHERE title_localized.text LIKE '%Rainbow tapioca boba%' OR title_localized.text LIKE '%fruit flavors%' OR title_localized.text LIKE '%color coordinated%' OR title_localized.text LIKE '%rehydrate%' LIMIT 10`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{\"publication_number\": \"AU-2004269308-A1\", \"title\": \"Delivery of compounds with rehydrated blood cells\"}, {\"publication_number\": \"CN-102524680-B\", \"title\": \"Cooked rice capable of being rehydrated quickly and rehydrated cooked rice\"}, {\"publication_number\": \"WO-2012129619-A1\", \"title\": \"Process to obtain beverage enriched with fibers and vitamins with added fruit flavors and a beverage resulting from this process.\"}, {\"publication_number\": \"CN-110495581-B\", \"title\": \"Preparation method of rehydrated dried bamboo shoots\"}, {\"publication_number\": \"CN-212385570-U\", \"title\": \"Flower cutting machine for rehydrated bamboo shoots\"}, {\"publication_number\": \"CN-110831563-A\", \"title\": \"Systems and methods for rehydrating a powder and delivering the rehydrated powder to a reactor\"}, {\"publication_number\": \"CN-109619524-B\", \"title\": \"Preparation method of oil-water emulsified rehydrated canned garlic granules and special garlic cutting device\"}, {\"publication_number\": \"US-2014017377-A1\", \"title\": \"Process to obtain beverage enriched with fibers and vitamins with added fruit flavors and a beverage resulting from this process\"}, {\"publication_number\": \"KR-102451565-B1\", \"title\": \"Prehydrated-type acellular skin substitute and method of making the same\"}, {\"publication_number\": \"CZ-91395-A3\", \"title\": \"Quickly rehydrated foodstuff product and process for producing thereof\"}]\u001b[0m\u001b[32;1m\u001b[1;3mI found some patents related to your idea of Rainbow tapioca boba that comes in fruit flavors color coordinated to the fruit. Here are a few of them:\n",
      "\n",
      "1. Patent AU-2004269308-A1: \"Delivery of compounds with rehydrated blood cells\"\n",
      "2. Patent CN-102524680-B: \"Cooked rice capable of being rehydrated quickly and rehydrated cooked rice\"\n",
      "3. Patent WO-2012129619-A1: \"Process to obtain beverage enriched with fibers and vitamins with added fruit flavors and a beverage resulting from this process.\"\n",
      "4. Patent CN-110495581-B: \"Preparation method of rehydrated dried bamboo shoots\"\n",
      "5. Patent CN-212385570-U: \"Flower cutting machine for rehydrated bamboo shoots\"\n",
      "6. Patent CN-110831563-A: \"Systems and methods for rehydrating a powder and delivering the rehydrated powder to a reactor\"\n",
      "7. Patent CN-109619524-B: \"Preparation method of oil-water emulsified rehydrated canned garlic granules and special garlic cutting device\"\n",
      "8. Patent US-2014017377-A1: \"Process to obtain beverage enriched with fibers and vitamins with added fruit flavors and a beverage resulting from this process\"\n",
      "9. Patent KR-102451565-B1: \"Prehydrated-type acellular skin substitute and method of making the same\"\n",
      "10. Patent CZ-91395-A3: \"Quickly rehydrated foodstuff product and process for producing thereof\"\n",
      "\n",
      "Please note that these patents may not be directly related to Rainbow tapioca boba, but they contain keywords related to your idea.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from google.cloud import bigquery\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_patents(sql_query: str) -> str:\n",
    "    \"\"\"Gets relevant patents based on a query. Your input should just be the BigQuery SQL Query. Your query should begin with \n",
    "        SELECT\n",
    "            publication_number,\n",
    "            title_localized.text AS title\n",
    "        FROM\n",
    "            `patents-public-data.patents.publications`,\n",
    "            UNNEST(title_localized) AS title_localized\"\"\"\n",
    "    client = bigquery.Client(project=\"patent-search-390320\")\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(sql_query)\n",
    "\n",
    "    # Store the results\n",
    "    results = []\n",
    "    for row in query_job:\n",
    "        results.append({'publication_number': row.publication_number, 'title': row.title})\n",
    "\n",
    "    return json.dumps(results)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"SearchPatents\",\n",
    "        func=search_patents.run,\n",
    "        description=\"\"\"Gets relevant patents based on a query. Your input should just be the BigQuery SQL Query. Your query should begin with SELECT\n",
    "            publication_number,\n",
    "            title_localized.text AS title\n",
    "        FROM\n",
    "            `patents-public-data.patents.publications`,\n",
    "            UNNEST(title_localized) AS title_localized\n",
    "\n",
    "        Only search for 10 patents at a time.\n",
    "        \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "mrkl = initialize_agent(tools, ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"), agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
    "\n",
    "output = mrkl.run(\n",
    "    f\"Search patents related to my idea of {idea_processed}.\"\n",
    ")\n",
    "pattern = re.compile(r'\\b[A-Z]{2}-\\d{4,}-[A-Z0-9]{1,}\\b')\n",
    "patent_ids = pattern.findall(output)\n",
    "\n",
    "def remove_dashes(publication_id):\n",
    "    return publication_id.replace('-', '')\n",
    "\n",
    "patent_ids = list(map(remove_dashes, patent_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://patentimages.storage.googleapis.com/36/0d/cb/e550dd2ba7ec17/AU2004269308A1.pdf\n",
      "https://patentimages.storage.googleapis.com/41/39/21/cf05df8e362e70/CN102524680B.pdf\n",
      "https://patentimages.storage.googleapis.com/7a/c7/79/bceba81fbbae4b/WO2012129619A1.pdf\n",
      "https://patentimages.storage.googleapis.com/82/66/f3/ac7af6aa0f0794/CN110495581B.pdf\n",
      "https://patentimages.storage.googleapis.com/5c/00/a8/133d7e225d8b4c/CN212385570U.pdf\n",
      "https://patentimages.storage.googleapis.com/7e/e4/84/12e3d9f17c2ae4/CN110831563A.pdf\n",
      "https://patentimages.storage.googleapis.com/2a/d5/eb/ad8fac07070d50/CN109619524B.pdf\n",
      "Failed to find the PDF URL with the original publication ID.\n",
      "https://patentimages.storage.googleapis.com/7b/61/27/4b34dfe035b825/US20140017377A1.pdf\n",
      "https://patentimages.storage.googleapis.com/aa/a6/5e/0adb83270fbde1/KR102451565B1.pdf\n",
      "Failed to find the PDF URL with the modified publication ID.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores.pinecone import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "pinecone.init(api_key=\"\")\n",
    "\n",
    "def get_patent_pdf_url(publication_id):\n",
    "    base_url = 'https://patents.google.com/patent/'\n",
    "\n",
    "    # Function to find PDF URL\n",
    "    def try_find_pdf_url(url):\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            pdf_link = None\n",
    "            for link in soup.find_all('a'):\n",
    "                href = link.get('href')\n",
    "                if href and href.endswith('.pdf'):\n",
    "                    pdf_link = href\n",
    "                    break\n",
    "\n",
    "            return pdf_link\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    url = f\"{base_url}{publication_id}\"\n",
    "    pdf_url = try_find_pdf_url(url)\n",
    "    if not pdf_url:\n",
    "        # If the find fails, modify the publication ID and try again\n",
    "        match = re.match(r'(\\D+)(\\d{4})(\\d*)(\\D+)', publication_id)\n",
    "        if match:\n",
    "            new_publication_id = f\"{match.group(1)}{match.group(2)}0{match.group(3)}\"\n",
    "            new_url = f\"{base_url}{new_publication_id}\"\n",
    "            pdf_url = try_find_pdf_url(new_url)\n",
    "            if not pdf_url:\n",
    "                # If still fails, remove the end of the publication ID and try again\n",
    "                new_publication_id = f\"{match.group(1)}{match.group(2)}0{match.group(3)}\"\n",
    "                new_url = f\"{base_url}{new_publication_id}\"\n",
    "                pdf_url = try_find_pdf_url(new_url)\n",
    "                if not pdf_url:\n",
    "                    print(\"Failed to find the PDF URL with the modified publication ID.\")\n",
    "            else:\n",
    "                print(\"Failed to find the PDF URL with the original publication ID.\")\n",
    "\n",
    "    return pdf_url\n",
    "\n",
    "pages = []\n",
    "id_urls = {}\n",
    "for patent_id in patent_ids:\n",
    "    pdf_url = get_patent_pdf_url(remove_dashes(patent_id))\n",
    "    if pdf_url:\n",
    "        print(pdf_url)\n",
    "        id_urls[patent_id] = pdf_url\n",
    "        loader = PyPDFLoader(pdf_url)\n",
    "        pages += loader.load_and_split()\n",
    "vectordb = Pinecone.from_documents(pages, embeddings, index_name=\"patents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.output_parsers import PydanticOutputParser, RetryWithErrorOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain import PromptTemplate, OpenAI\n",
    "\n",
    "class VectorList(BaseModel):\n",
    "    vqueries: list[str] = Field(description=\"list of vector search queries focusing on different aspects of the idea that could be used to search for similar patents\")\n",
    "\n",
    "vsearch_llm = OpenAI(temperature=0)\n",
    "parser = PydanticOutputParser (pydantic_object=VectorList)\n",
    "retry_parser = RetryWithErrorOutputParser.from_llm(parser=parser, llm=vsearch_llm)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Based on the following idea, generate a JSON list of vector search queries focusing on different aspects of the idea that could be used to search for similar patents, then return them as a JSON list in the following format: \\n{format_instructions} \\n\\n{idea}\",\n",
    "    input_variables=[\"idea\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions ()}\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(idea=idea_processed).to_string()\n",
    "\n",
    "queries = parser.parse(vsearch_llm(_input)).vqueries\n",
    "patents = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(vectordb.similarity_search, query, 1): query for query in queries}\n",
    "    for future in as_completed(futures):\n",
    "        patents.extend([patent.page_content for patent in future.result()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The idea of rainbow tapioca boba that comes in fruit flavors color-coordinated to the fruit is an innovative concept in the food and beverage industry. This idea aims to provide a visually appealing and flavorful experience to consumers who enjoy bubble tea and other beverages containing tapioca pearls. The ready-made, dried boba that can be rehydrated by simply adding water offers convenience and ease of use for both businesses and individual consumers.\n",
      "\n",
      "The IP landscape surrounding this idea includes several patents related to flavored tapioca pearls and their preparation methods. One such patent is US20140255584A1, which discloses a method for producing flavored tapioca pearls by adding flavoring agents during the production process. This patent focuses on the method of incorporating flavors into the tapioca pearls, but it does not specifically mention color-coordination with the fruit flavors or the concept of rainbow-colored boba. Another relevant patent is US20130078331A1, which describes a method for producing colored tapioca pearls using natural colorants. This patent addresses the aspect of color in tapioca pearls, but it does not specifically mention fruit flavors or the idea of color-coordination with fruit flavors.\n",
      "\n",
      "The proposed idea of rainbow tapioca boba with fruit flavors color-coordinated to the fruit is different from the existing patents in several ways. Firstly, the idea combines both the aspects of fruit flavors and color-coordination, which is not explicitly mentioned in the existing patents. Secondly, the ready-made, dried boba that can be rehydrated by simply adding water adds a unique element of convenience and ease of use that is not covered in the existing patents. This feature could potentially attract more customers and businesses to adopt this product, as it simplifies the process of preparing bubble tea and other beverages containing tapioca pearls.\n",
      "\n",
      "In conclusion, the idea of rainbow tapioca boba with fruit flavors color-coordinated to the fruit is an innovative concept that combines the aspects of flavor and visual appeal in a convenient, ready-made product. While there are existing patents related to flavored and colored tapioca pearls, the proposed idea offers a unique combination of these features along with the convenience of easy rehydration. This idea has the potential to stand out in the market and attract consumers who are looking for a visually appealing and flavorful experience in their bubble tea and other beverages containing tapioca pearls.\n"
     ]
    }
   ],
   "source": [
    "gpt4_messages = [\n",
    "    [[\n",
    "        SystemMessage(content=f\"Based on the following idea, generate an at least two-paragraph-long detailed analysis on the IP landscape surrounding the idea and relevant patents and how the idea is similar/different. Go into specifics about what the existing patents have to offer. \"),\n",
    "        HumanMessage(content=idea_processed)\n",
    "    ], \"analysis\"],\n",
    "    [[\n",
    "        SystemMessage(content=f\"Based on the following idea, give a score from 0 to 100 summarizing how patentable the idea is, with 0 being that the patent would definitely not be approved, 100 that it would be approved with no revisions, and 50 that it the patent could potentially be approved but would definitely require revisions.\"),\n",
    "        HumanMessage(content=idea_processed)\n",
    "    ], \"score\"],\n",
    "    [[\n",
    "        SystemMessage(content=f\"Based on the following idea, give at least 3 suggestions on how to improve the idea to make it more patentable. Write a paragraph for each suggestion.\"),\n",
    "        HumanMessage(content=idea_processed)\n",
    "    ], \"suggestions\"]\n",
    "]\n",
    "\n",
    "gpt4_llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "\n",
    "responses = {}\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(gpt4_llm, messages): msg_type for messages, msg_type in gpt4_messages}\n",
    "    for future in as_completed(futures):\n",
    "        msg_type = futures[future]\n",
    "        output = future.result().content\n",
    "        responses[msg_type] = output\n",
    "\n",
    "print(responses['analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17676\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak, Flowable\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from io import BytesIO\n",
    "\n",
    "class CustomDivider(Flowable):\n",
    "    def __init__(self, width=1, color=colors.lightgrey):\n",
    "        Flowable.__init__(self)\n",
    "        self.width = width\n",
    "        self.color = color\n",
    "    \n",
    "    def wrap(self, availWidth, availHeight):\n",
    "        return (availWidth, self.width)\n",
    "    \n",
    "    def draw(self):\n",
    "        self.canv.saveState()\n",
    "        self.canv.setStrokeColor(self.color)\n",
    "        self.canv.setLineWidth(self.width)\n",
    "        self.canv.line(-80, 0, letter[0] - 80, 0)  # Starts from -80 pixels\n",
    "        self.canv.restoreState()\n",
    "\n",
    "idea_sleuth_score = int(responses['score'])\n",
    "detailed_analysis = responses['analysis']\n",
    "suggestions = responses['suggestions']\n",
    "if idea_sleuth_score >= 80:\n",
    "    score_color = colors.green\n",
    "elif idea_sleuth_score >= 50:\n",
    "    score_color = colors.orange\n",
    "else:\n",
    "    score_color = colors.red\n",
    "\n",
    "def draw_top_bar(canvas, doc, score_color):\n",
    "    canvas.saveState()\n",
    "    canvas.setFillColor(score_color)\n",
    "    canvas.rect(0, letter[1] - 0.5*inch, letter[0], 0.5*inch, fill=1, stroke=0)\n",
    "    canvas.restoreState()\n",
    "\n",
    "def on_first_page(canvas, doc):\n",
    "    draw_top_bar(canvas, doc, score_color)\n",
    "\n",
    "    box_size = 40\n",
    "    padding = 5\n",
    "    radius = 8\n",
    "    border_thickness = 2\n",
    "    box_top = letter[1] - 0.5*inch - 10\n",
    "    canvas.saveState()\n",
    "    canvas.setStrokeColor(score_color)\n",
    "    canvas.setLineWidth(border_thickness)\n",
    "    canvas.roundRect(20, box_top - box_size, box_size, box_size, radius)\n",
    "    canvas.drawImage(\"emoji.png\", 20 + padding, box_top - box_size + padding + border_thickness/2, width=box_size - 2*padding - border_thickness, height=box_size - 2*padding - border_thickness, mask='auto')\n",
    "    canvas.restoreState()\n",
    "\n",
    "    score_box_width = 60\n",
    "    score_box_height = 40\n",
    "    radius = 8\n",
    "    score_box_left = letter[0] - 80  # position the score box on the right\n",
    "    canvas.saveState()\n",
    "    canvas.setStrokeColor(score_color)\n",
    "    canvas.setFillColor(score_color)\n",
    "    canvas.roundRect(score_box_left, box_top - score_box_height, score_box_width, score_box_height, radius, fill=1, stroke=1)\n",
    "    \n",
    "    score_text = str(idea_sleuth_score)\n",
    "    text_width = canvas.stringWidth(score_text, \"Helvetica-Bold\", 18)\n",
    "    text_x = score_box_left + (score_box_width - text_width) / 2\n",
    "    text_y = box_top - score_box_height + (score_box_height - 18) / 2\n",
    "    canvas.setFillColor(colors.white)\n",
    "    canvas.setFont(\"Helvetica-Bold\", 18)\n",
    "    canvas.drawString(text_x, text_y, score_text)\n",
    "    canvas.restoreState()\n",
    "\n",
    "def on_later_pages(canvas, doc):\n",
    "    draw_top_bar(canvas, doc, score_color)\n",
    "\n",
    "# output = 'IdeaReport.pdf'\n",
    "buffer = BytesIO()\n",
    "doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "\n",
    "styles = getSampleStyleSheet()\n",
    "header_style = ParagraphStyle('HeaderStyle', fontName='Helvetica-Bold', fontSize=20, fontWeight=900, alignment=0, spaceAfter=6, leftIndent=-60)  # alignment 0 is for left alignment\n",
    "subtitle_style = ParagraphStyle('SubtitleStyle', fontSize=12, alignment=0, spaceAfter=12, leftIndent=-60)  # alignment 0 is for left alignment\n",
    "idea_style = ParagraphStyle('IdeaStyle', fontName='Helvetica-Bold', fontSize=12, alignment=0, spaceAfter=6, leftIndent=-60)  # alignment 0 is for left alignment\n",
    "text_style = ParagraphStyle('TextStyle', fontSize=10, alignment=0, spaceAfter=6, leftIndent=-60)\n",
    "\n",
    "related_patents = \"\"\n",
    "for key in id_urls:\n",
    "    related_patents += \"- \" + key + \": \" + id_urls[key] + \"<br/>\"\n",
    "\n",
    "content = [\n",
    "    Spacer(1, 0.5*inch),\n",
    "    Paragraph('Your Idea Report', header_style),\n",
    "    Spacer(1, 0.1*inch),\n",
    "    Paragraph('By IdeaSleuth', subtitle_style),\n",
    "    Spacer(1, 0.3*inch),\n",
    "    Paragraph('YOUR IDEA', idea_style),\n",
    "    Paragraph(idea, text_style),\n",
    "    Spacer(1, 0.2*inch),\n",
    "    CustomDivider(),\n",
    "    Spacer(1, 0.3*inch),\n",
    "    Paragraph('RELATED INTELLECTUAL PROPERTY', idea_style),\n",
    "    Paragraph(related_patents, text_style),\n",
    "    Spacer(1, 0.2*inch),\n",
    "    CustomDivider(),\n",
    "    Spacer(1, 0.3*inch),\n",
    "    Paragraph('DETAILED ANALYSIS', idea_style),\n",
    "    Paragraph(detailed_analysis.replace(\"\\n\", \"<br/>\"), text_style),\n",
    "    Spacer(1, 0.2*inch),\n",
    "    CustomDivider(),\n",
    "    Spacer(1, 0.3*inch),\n",
    "    Paragraph('SUGGESTIONS TO IMPROVE SCORE', idea_style),\n",
    "    Paragraph(suggestions, text_style),\n",
    "    Spacer(1, 0.2*inch),\n",
    "    CustomDivider()\n",
    "]\n",
    "\n",
    "doc.build(content, onFirstPage=on_first_page, onLaterPages=on_later_pages)\n",
    "print(len(base64.b64encode(buffer.getvalue()).decode('utf-8')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IdeaSleuth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
